#Code for GUI

from Tkinter import *
import tkMessageBox    #the * in previous line should already import this but need this line b/c of line 10 and 32

def save():
    text = E1.get() + "\n" + "glocations, " + E2.get() + "\n" + E3.get() + "\n" + E4.get()  
    with open("QueryResults.txt", "w") as f:
        f.writelines(text)

def saveMessage():
    tkMessageBox.showinfo("Query Message", "Success! Query in progress.")

def buttonClicked():
    save()
    saveMessage()
    
      
top = Tk(className = "NYTimes Article Search GUI")
top.minsize(width = 400, height = 100)

Label(top, text = "Search Words").grid(row=0)     #Searches through Headline, Body, and Byline
Label(top, text = "Geographic Location (Only one)").grid(row=1)    #By only having the user input 1 location, we can use this location to zoom in the map
Label(top, text = "Start Date (YYYYMMDD)").grid(row=2)
Label(top, text = "End Date (YYYYMMDD)").grid(row=3)

E1 = Entry(top)
E2 = Entry(top)
E3 = Entry(top)
E4 = Entry(top)

E1.grid(row=0, column=1)
E2.grid(row=1, column=1)
E3.grid(row=2, column=1)
E4.grid(row=3, column=1)


Button(top, text = "GO", command = buttonClicked).grid(row=4, column=0)


top.mainloop()





folderPath = "F:\\Tom_Smith_Python_Programming_Fall_2016\\Module_2_Comp_Programming_for_GIS\\Final_Project\\"
inputFN = "QueryResults.txt"
inputFilePath = folderPath + inputFN

f1 = open(inputFilePath, "r")
fileString = f1.read()
f1.close()

queryList = fileString.split("\n")



wordSearch = queryList[0]
print wordSearch
geoLocation = queryList[1].split(", ")
if geoLocation[1] == "":
    geoLocDict = "No location specified"     #then see if location exists in first word of first line of article and use that
    print geoLocDict
else:
    geoLocDict = {geoLocation[0]:geoLocation[1]}
    print geoLocDict
searchDateStart = queryList[2]
print searchDateStart
searchDateEnd = queryList[3]
print searchDateEnd



 
#make sure blank gui inputs are .........dealt with    if line = "", don't add it to list or something
#figure out how to connect the article search api with the geographic api to get the coordinates associated with the queried articles so that we can map them
#also figure out how to make a dictionary from the field query types such that user inputs for the field query lines in text file are added as values for the correct
#field query type and if there are multiple inputs for one line (ex. word, word, word) make that value a list of those words fq = {headline:Obama, body:[whale, snake]}



"""
check to see if i can have multiple inputs for glocations: or if i need to use
glocations.contains for when there is multiple inputs (can just say that only one location
input allowed to make things easy and allow the map to zoom to only one area)
"""


#instead of saving user inputs, coud use the function entry = E1.get()


'''
if user leave blank, make sure that is okay
1 key, multiple values for glocations.contains, make sure that works, have to make a list for values

if/while/for functions so that each time the go button is clicked, saves a new text file,
have the number at end of text file name increase by 1 or something (not sure how to do)
'''




'''
geoparcer API service - used GeoNames

or 

if user input location into gui, use to zoom for map and query articles

if no user location input (""), see if there is a location name as the first
word in the first line of the article, if there isn't, location will be New York City and use that to zoom for map
NYC used for geocoding.

if no user location input (""), if there is a location name as the first word in
the first line of the article, run it through the list of domestic city, state, state abriviation to
see if match for each article, and if there is, map based on this, if not, do NYC again










##############################################################################################

from nytimesarticle import articleAPI # import NYT Article Search API

api = articleAPI('8a7bed87ddf84a98bd560ba2eb3ba3fb') # API key

import requests # import requests library to access URL content

articles = api.search(fq = {'headline': '*', 'glocations.contains': 'North Dakota'}, begin_date = '20161119', end_date = '20161123', fl = ['web_url', 'lead_paragraph', 'abstract', 'source', 'headline', 'pub_date', 'byline'])

print articles['response']['docs'][0]['headline']['main']
print articles['response']['docs'][0]['web_url']

from geopy.geocoders import Nominatim
geolocator = Nominatim()
location = geolocator.geocode('North Dakota')

#print '\n' + str(location.raw)
print '\n'
print location.raw['lon'], location.raw['lat'],location.raw['boundingbox']

###

import requests, json
from nytimesarticle import articleAPI
from geopy.geocoders import Nominatim
from HTMLParser import HTMLParser
from bs4 import BeautifulSoup

url = 'https://geoparser.io/api/geoparser' # URL for Geoparser.io service
headers = {'Authorization': 'apiKey 96371282185817752'} # API key for Geoparser
api = articleAPI('8a7bed87ddf84a98bd560ba2eb3ba3fb') # API key for ArticleSearch API

articleURL = 'http://www.nytimes.com/2016/11/27/us/politics/steve-bannon-white-house.html?hp&action=click&pgtype=Homepage&clickSource=image&module=b-lede-package-region&region=top-news&WT.nav=top-news&_r=0' # Article URL to pass through HTML parser
r = requests.get(articleURL) # Create Response object to make requests

HTML = BeautifulSoup(r.text, 'html.parser') # Create object to parse HTML from webpage using Beautiful Soup and HTMLParser standard library

articleTxt = HTML.body.get_text() # Get and format all body text

"""
txtList = []
for ch in range(500, len(articleTxt)):
    txtList.append(ch)
    print txtList
data = {'inputText': articleTxt}

resp = requests.post(url, headers=headers, data=data)

print json.dumps(resp.json())"""

print articleTxt
###
